{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2906809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "import math\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20ac3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(raw_review):  \n",
    "    raw_review = raw_review.lower();\n",
    "    raw_review = re.sub(r\"<br|/>\", \" \", raw_review)\n",
    "    review = re.sub(r\",|\\(|\\)|\\[|\\]|<|>|-|!|\\?|\\\"|â€œ|:|\\*|\\.|#\", \" \", raw_review)\n",
    "    return review\n",
    "\n",
    "def read_dir(dir_path):\n",
    "    os.chdir(dir_path)\n",
    "    review_list = []\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{dir_path}/{file}\"\n",
    "            with open(file_path, 'r') as f:\n",
    "                s = f.read()\n",
    "                #print(s)\n",
    "                s = clean(s)\n",
    "                #print(s)\n",
    "                review_list.append(s)\n",
    "    return review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5be01edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 12500 12500 12500\n"
     ]
    }
   ],
   "source": [
    "train_pos_dir = \"/Users/zhitaoliang/Documents/study/LP3/TME286/A1/aclImdb/train/pos\"\n",
    "train_neg_dir = \"/Users/zhitaoliang/Documents/study/LP3/TME286/A1/aclImdb/train/neg\"\n",
    "train_pos_list = read_dir(train_pos_dir)\n",
    "train_neg_list = read_dir(train_neg_dir)\n",
    "\n",
    "test_pos_dir = \"/Users/zhitaoliang/Documents/study/LP3/TME286/A1/aclImdb/test/pos\"\n",
    "test_neg_dir = \"/Users/zhitaoliang/Documents/study/LP3/TME286/A1/aclImdb/test/neg\"\n",
    "test_pos_list = read_dir(test_pos_dir)\n",
    "test_neg_list = read_dir(test_neg_dir)\n",
    "\n",
    "print(len(train_pos_list), len(train_neg_list), len(test_pos_list), len(test_neg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aa9327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    token_with_logdis_dic = {}\n",
    "\n",
    "    def tokenize_and_count(self, review_list):\n",
    "        token_list = []\n",
    "        for review in review_list:\n",
    "            token_list += review.split()\n",
    "        token_counter = Counter(token_list)\n",
    "        return token_counter\n",
    "\n",
    "    def cal_gamma_of_token(self, pos_token_counter, neg_token_counter):\n",
    "        self.token_with_logdis_dic = {}\n",
    "        for token in pos_token_counter:\n",
    "            if(neg_token_counter[token] == 0):\n",
    "                continue\n",
    "            pos_count = pos_token_counter[token]\n",
    "            neg_count = neg_token_counter[token]\n",
    "            self.token_with_logdis_dic[token] = math.log10(float(pos_count/neg_count))\n",
    "        output_file = \"/Users/zhitaoliang/Documents/study/LP3/TME286/A1/TokenList.txt\"\n",
    "        sort_by_value = sorted(self.token_with_logdis_dic.items(), key=lambda x:x[1])\n",
    "        print(sort_by_value[0:30])\n",
    "        print(sort_by_value[len(sort_by_value)-31:len(sort_by_value)-1])\n",
    "        self.token_with_logdis_dic = OrderedDict(sorted(self.token_with_logdis_dic.items()))\n",
    "        \n",
    "        f= open(output_file,\"x\")\n",
    "        f= open(output_file,\"w+\")\n",
    "        for token in self.token_with_logdis_dic:\n",
    "            f.write(token + \"\\t\" + str(self.token_with_logdis_dic[token]) + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "    def fit(self, pos_review_list, neg_review_list):\n",
    "        pos_counter = self.tokenize_and_count(pos_review_list)\n",
    "        neg_counter = self.tokenize_and_count(neg_review_list)\n",
    "        self.cal_gamma_of_token(pos_counter, neg_counter)\n",
    "    \n",
    "    def classify_review(self, review):\n",
    "        token_seq = review.split()\n",
    "        sum_gamma = 0\n",
    "        predicted_label = -1\n",
    "        for token in token_seq:\n",
    "            if token in self.token_with_logdis_dic:\n",
    "                sum_gamma += self.token_with_logdis_dic[token]\n",
    "        if sum_gamma > 0:\n",
    "            predicted_label = 1\n",
    "        else:\n",
    "            predicted_label = 0\n",
    "        return predicted_label\n",
    "    \n",
    "    def classify(self, review_list):\n",
    "        pre_label_list = []\n",
    "        for review in review_list:\n",
    "            predicted_label = self.classify_review(review)\n",
    "            pre_label_list.append(predicted_label)\n",
    "        return pre_label_list\n",
    "    \n",
    "    def score(self, predicted_labels, actual_labels):\n",
    "        #precision = metrics.precision_score(actual_labels, predicted_labels)\n",
    "        #recall = metrics.recall_score(actual_labels, predicted_labels)\n",
    "        accuracy = metrics.accuracy_score(actual_labels, predicted_labels)\n",
    "        #f1score = metrics.f1_score(actual_labels, predicted_labels)\n",
    "        classification_report = metrics.classification_report(actual_labels, predicted_labels)\n",
    "        \n",
    "        return accuracy, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "290d306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('boll', -2.1072099696478683), ('2/10', -2.093421685162235), ('uwe', -2.0), ('beowulf', -1.7481880270062005), ('ajay', -1.662757831681574), ('seagal', -1.656417653650555), ('wayans', -1.6532125137753437), ('4/10', -1.6384892569546374), ('scarecrows', -1.6334684555795866), ('dahmer', -1.6232492903979006), ('awfulness', -1.5797835966168101), ('grendel', -1.568201724066995), ('steaming', -1.568201724066995), ('3/10', -1.5314789170422551), ('segal', -1.5314789170422551), ('deathstalker', -1.5185139398778875), ('interminable', -1.4771212547196624), ('forwarding', -1.462397997898956), ('sabretooth', -1.4471580313422192), ('gamera', -1.4313637641589874), ('picker', -1.414973347970818), ('dreck', -1.414973347970818), ('devgan', -1.414973347970818), ('unwatchable', -1.41077723337721), ('stinker', -1.3847117429382825), ('razzie', -1.3802112417116061), ('nada', -1.3802112417116061), ('mst3k', -1.3679767852945943), ('nostril', -1.3617278360175928), ('demi', -1.3424226808222062)]\n",
      "[(\"tony's\", 1.414973347970818), ('hayworth', 1.414973347970818), ('pang', 1.414973347970818), ('emil', 1.4313637641589874), ('ashraf', 1.4313637641589874), ('harriet', 1.4393326938302626), ('conroy', 1.4471580313422192), ('dench', 1.4471580313422192), ('korda', 1.4471580313422192), ('excellently', 1.462397997898956), ('mathieu', 1.462397997898956), ('jabba', 1.462397997898956), ('aviv', 1.462397997898956), ('partition', 1.462397997898956), ('stevenson', 1.4771212547196624), ('hickock', 1.4771212547196624), ('aiello', 1.4913616938342726), (\"victoria's\", 1.505149978319906), ('callahan', 1.505149978319906), ('luzhin', 1.5185139398778875), ('7/10', 1.5228787452803376), ('taker', 1.5314789170422551), ('clutter', 1.5563025007672873), ('anchors', 1.5563025007672873), ('giovanna', 1.591064607026499), ('lindy', 1.6020599913279623), ('feinstone', 1.6020599913279623), ('philo', 1.6334684555795864), ('gundam', 1.6384892569546374), ('iturbi', 1.6812412373755872)]\n",
      "25000 25000 25000 25000\n"
     ]
    }
   ],
   "source": [
    "movie_review_classifier = Classifier()\n",
    "# fit classifier\n",
    "movie_review_classifier.fit(train_pos_list, train_neg_list)\n",
    "# classify\n",
    "predicted_train_labels = movie_review_classifier.classify(train_pos_list) + movie_review_classifier.classify(train_neg_list)\n",
    "predicted_test_labels = movie_review_classifier.classify(test_pos_list) + movie_review_classifier.classify(test_neg_list)\n",
    "\n",
    "actual_train_labels = [1]*len(train_pos_list) + [0]*len(train_neg_list)\n",
    "actual_test_labels = [1]*len(test_pos_list) + [0]*len(test_neg_list)\n",
    "\n",
    "print(len(predicted_train_labels), len(predicted_test_labels), len(actual_train_labels), len(actual_test_labels))\n",
    "# score\n",
    "train_score = movie_review_classifier.score(predicted_train_labels, actual_train_labels)\n",
    "test_score = movie_review_classifier.score(predicted_test_labels, actual_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d5afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set result\n",
      "Accuracy: 0.87808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87     12500\n",
      "           1       0.86      0.91      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "\n",
      "Test set result\n",
      "Accuracy: 0.8272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82     12500\n",
      "           1       0.81      0.85      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set result\\nAccuracy:\", train_score[0])\n",
    "print(train_score[1])\n",
    "print(\"\\nTest set result\\nAccuracy:\", test_score[0])\n",
    "print(test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87667a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739b2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
